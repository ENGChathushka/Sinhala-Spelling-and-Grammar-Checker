{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow5Pait7BbQw",
        "outputId": "91452050-bf2b-423d-c509-7afb8e5be4a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt7OmpwfBgzn",
        "outputId": "1d569036-a4d9-4485-b224-e3bb5d8c7213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m194.6/244.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from transformers import get_scheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load dataset\n",
        "data_path = '/content/drive/MyDrive/AI/Project/Grammer_data_set.xlsx'\n",
        "data = pd.read_excel(data_path)\n",
        "data.columns = ['Sentence', 'True_Sentence', 'Label']\n",
        "\n",
        "# Preprocess dataset\n",
        "def encode_labels(label):\n",
        "    \"\"\"Encode categorical labels into integers.\"\"\"\n",
        "    return int(label)\n",
        "\n",
        "data['Label'] = data['Label'].apply(encode_labels)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    data['Sentence'], data['Label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Tokenize using BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "class GrammarDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=64):  # Reduced max_len\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts.iloc[idx]\n",
        "        label = self.labels.iloc[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = GrammarDataset(train_texts, train_labels, tokenizer)\n",
        "test_dataset = GrammarDataset(test_texts, test_labels, tokenizer)\n",
        "\n",
        "# Create data loaders with larger batch size\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Load pre-trained BERT model for classification\n",
        "num_classes = len(data['Label'].unique())\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-multilingual-cased',\n",
        "    num_labels=num_classes\n",
        ").to(device)\n",
        "\n",
        "# Freeze BERT layers to reduce training time\n",
        "for param in model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "num_training_steps = len(train_loader) * 3  # 3 epochs\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "# Use mixed precision for faster training\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training loop with fewer epochs\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Save the model\n",
        "model_save_path = '/content/drive/MyDrive/AI/Project/results/bert_grammar_spell_model.pt'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLBIKXgYFpyM",
        "outputId": "36021b62-8774-4ef0-d33e-a331a70c29aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "<ipython-input-7-10690c60cbc4>:88: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "<ipython-input-7-10690c60cbc4>:101: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.6700274765491485\n",
            "Epoch 2/10, Loss: 0.6533434569835663\n",
            "Epoch 3/10, Loss: 0.6428937152028084\n",
            "Epoch 4/10, Loss: 0.6396181434392929\n",
            "Epoch 5/10, Loss: 0.6411849915981293\n",
            "Epoch 6/10, Loss: 0.6341244257986546\n",
            "Epoch 7/10, Loss: 0.6421281337738037\n",
            "Epoch 8/10, Loss: 0.6383662566542625\n",
            "Epoch 9/10, Loss: 0.6393151909112931\n",
            "Epoch 10/10, Loss: 0.6396233320236206\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80       211\n",
            "           1       0.00      0.00      0.00       105\n",
            "\n",
            "    accuracy                           0.67       316\n",
            "   macro avg       0.33      0.50      0.40       316\n",
            "weighted avg       0.45      0.67      0.53       316\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/AI/Project/results/bert_grammar_spell_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import difflib\n",
        "from docx import Document\n",
        "\n",
        "# Load the trained BERT model\n",
        "model_save_path = '/content/drive/MyDrive/AI/Project/results/bert_grammar_spell_model.pt'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_classes = 2  # Adjust based on your dataset labels (e.g., 0: Incorrect, 1: Correct)\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-multilingual-cased',\n",
        "    num_labels=num_classes\n",
        ").to(device)\n",
        "model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Load the dictionary from .docx file\n",
        "def load_dictionary_from_docx(file_path):\n",
        "    document = Document(file_path)\n",
        "    words = []\n",
        "    for paragraph in document.paragraphs:\n",
        "        words.extend(paragraph.text.split())\n",
        "    return set(words)\n",
        "\n",
        "dictionary_path = '/content/drive/MyDrive/AI/Project/Spell_correction_data.docx'\n",
        "dictionary = load_dictionary_from_docx(dictionary_path)\n",
        "print(f\"Loaded {len(dictionary)} words from the dictionary.\\n\")\n",
        "\n",
        "# Grammar rules for sentence endings\n",
        "def check_grammar(sentence):\n",
        "    words = sentence.split()\n",
        "\n",
        "    # Rule 1: Starts with 'මම' -> Ends with 'මි'\n",
        "    if words[0] == \"මම\":\n",
        "        if not words[-1].endswith(\"මි\"):\n",
        "            return False, f\"{words[0]} ---> මි\"\n",
        "\n",
        "    # Rule 2: Starts with 'අපි' -> Ends with 'මු'\n",
        "    elif words[0] == \"අපි\":\n",
        "        if not words[-1].endswith(\"මු\"):\n",
        "            return False, f\"{words[0]} ---> මු\"\n",
        "\n",
        "    # Rule 3: Starts with any word -> Ends with 'යි'\n",
        "    else:\n",
        "        if not words[-1].endswith(\"යි\"):\n",
        "            return False, f\"{words[0]} ---> යි\"\n",
        "\n",
        "    return True, None\n",
        "\n",
        "# Spelling checking functions\n",
        "def detect_errors(word, dictionary):\n",
        "    return word if word not in dictionary else None\n",
        "\n",
        "def suggest_correction(word, dictionary):\n",
        "    closest_match = difflib.get_close_matches(word, dictionary, n=1)\n",
        "    return closest_match[0] if closest_match else word\n",
        "\n",
        "# Grammar validation function using BERT\n",
        "def check_grammar_with_bert(sentence, model, tokenizer, device, max_len=64):\n",
        "    encoding = tokenizer(\n",
        "        sentence,\n",
        "        max_length=max_len,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        prediction = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    return prediction == 1\n",
        "\n",
        "# Interactive function for sentence checking\n",
        "def check_user_input():\n",
        "    print(\"👨‍💻 Enter a sentence to check for spelling and grammar. Type 'exit' to stop.\\n\")\n",
        "\n",
        "    while True:\n",
        "        sentence = input(\"✍️ Enter a sentence: \")\n",
        "\n",
        "        if sentence.lower() == 'exit':\n",
        "            print(\"\\nExiting... Goodbye! 👋\\n\")\n",
        "            break\n",
        "\n",
        "        print(\"\\n🔍 Checking spelling and grammar...\\n\")\n",
        "\n",
        "        # Step 1: Spell check\n",
        "        words = sentence.split()\n",
        "        if len(words) > 1:\n",
        "            misspelled_word = detect_errors(words[1], dictionary)\n",
        "            if misspelled_word:\n",
        "                corrected_word = suggest_correction(misspelled_word, dictionary)\n",
        "                print(f\"❌ Spelling mistake detected in the second word: {misspelled_word}\")\n",
        "                print(f\"🔄 Corrected second word: {corrected_word}\")\n",
        "            else:\n",
        "                print(\"✔️ No spelling mistakes detected in the second word.\")\n",
        "        else:\n",
        "            print(\"⚠️ Insufficient words for spell-checking.\")\n",
        "\n",
        "        # Step 2: Grammar check\n",
        "        is_correct, correction = check_grammar(sentence)\n",
        "        if is_correct:\n",
        "            print(\"✔️ The sentence is grammatically correct.\")\n",
        "        else:\n",
        "            print(\"❌ The sentence is grammatically incorrect.\")\n",
        "            print(f\"🔄 Suggested correction based on grammar rules: {correction}\")\n",
        "\n",
        "        # Step 3: BERT Grammar Model Check\n",
        "        bert_prediction = check_grammar_with_bert(sentence, model, tokenizer, device)\n",
        "        if bert_prediction:\n",
        "            print(\"✔️ BERT Prediction: The sentence is grammatically correct.\")\n",
        "        else:\n",
        "            print(\"❌ BERT Prediction: The sentence is grammatically incorrect.\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Run the function\n",
        "check_user_input()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_rOG1KKMFrl",
        "outputId": "20c6266f-f675-484a-f9a1-7f04444f0da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-15-b62aaa7cc70f>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_save_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 182 words from the dictionary.\n",
            "\n",
            "👨‍💻 Enter a sentence to check for spelling and grammar. Type 'exit' to stop.\n",
            "\n",
            "✍️ Enter a sentence: අපි පලතර කයි\n",
            "\n",
            "🔍 Checking spelling and grammar...\n",
            "\n",
            "❌ Spelling mistake detected in the second word: පලතර\n",
            "🔄 Corrected second word: පලතුරු\n",
            "❌ The sentence is grammatically incorrect.\n",
            "🔄 Suggested correction based on grammar rules: අපි ---> මු\n",
            "❌ BERT Prediction: The sentence is grammatically incorrect.\n",
            "\n",
            "==================================================\n",
            "\n",
            "✍️ Enter a sentence: අපි ගත කියමි\n",
            "\n",
            "🔍 Checking spelling and grammar...\n",
            "\n",
            "❌ Spelling mistake detected in the second word: ගත\n",
            "🔄 Corrected second word: ගීත\n",
            "❌ The sentence is grammatically incorrect.\n",
            "🔄 Suggested correction based on grammar rules: අපි ---> මු\n",
            "❌ BERT Prediction: The sentence is grammatically incorrect.\n",
            "\n",
            "==================================================\n",
            "\n",
            "✍️ Enter a sentence: ඇය පල් කමු\n",
            "\n",
            "🔍 Checking spelling and grammar...\n",
            "\n",
            "❌ Spelling mistake detected in the second word: පල්\n",
            "🔄 Corrected second word: ඇපල්\n",
            "❌ The sentence is grammatically incorrect.\n",
            "🔄 Suggested correction based on grammar rules: ඇය ---> යි\n",
            "❌ BERT Prediction: The sentence is grammatically incorrect.\n",
            "\n",
            "==================================================\n",
            "\n",
            "✍️ Enter a sentence: මම කත්තු කමු\n",
            "\n",
            "🔍 Checking spelling and grammar...\n",
            "\n",
            "❌ Spelling mistake detected in the second word: කත්තු\n",
            "🔄 Corrected second word: කොත්තු\n",
            "❌ The sentence is grammatically incorrect.\n",
            "🔄 Suggested correction based on grammar rules: මම ---> මි\n",
            "❌ BERT Prediction: The sentence is grammatically incorrect.\n",
            "\n",
            "==================================================\n",
            "\n",
            "✍️ Enter a sentence: තාත්තා ගවන්වදුලයට සවන්දෙයි\n",
            "\n",
            "🔍 Checking spelling and grammar...\n",
            "\n",
            "❌ Spelling mistake detected in the second word: ගවන්වදුලයට\n",
            "🔄 Corrected second word: ගුවන්විදුලියට\n",
            "✔️ The sentence is grammatically correct.\n",
            "❌ BERT Prediction: The sentence is grammatically incorrect.\n",
            "\n",
            "==================================================\n",
            "\n",
            "✍️ Enter a sentence: exit\n",
            "\n",
            "Exiting... Goodbye! 👋\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5kcuSgGSOdjb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}